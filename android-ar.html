<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <title>AR Image Anchor (Android)</title>
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <style>
    body{margin:0;overflow:hidden;background:#000;font-family:system-ui,Arial,sans-serif}
    #hud{position:fixed;top:10px;left:50%;transform:translateX(-50%);color:#fff;background:rgba(0,0,0,.55);padding:6px 10px;border-radius:8px;font-size:13px;z-index:10}
  </style>
</head>
<body>
  <div id="hud">Vise le logo ESGT imprimé…</div>

  <a-scene
    vr-mode-ui="enabled: false"
    webxr="mode: ar; requiredFeatures: image-tracking,anchors; optionalFeatures: hit-test; overlayElement: body; sessionMode: immersive-ar">

    <!-- On précharge le glb -->
    <a-assets timeout="45000">
      <a-asset-item id="model" src="./modele.glb" crossorigin="anonymous"></a-asset-item>
    </a-assets>

    <!-- Un “pivot” qu’on attachera à l’ancre (origine = centre de l’image) -->
    <a-entity id="targetPivot" visible="false"></a-entity>

    <!-- Ton objet rendu avec un OFFSET par rapport à l’origine cible -->
    <!-- Ici, exemple: 30 cm à droite (X), 0 cm en Y, 40 cm “devant” (Z négatif dans A-Frame) -->
    <a-entity id="objet"
              gltf-model="#model"
              position="0.30 0 -0.40"
              rotation="0 0 0"
              scale="0.3 0.3 0.3"
              visible="false">
    </a-entity>

    <a-camera look-controls="enabled:true"></a-camera>
  </a-scene>

  <script>
    const scene   = document.querySelector('a-scene');
    const hud     = document.getElementById('hud');
    const pivot   = document.getElementById('targetPivot');
    const objet   = document.getElementById('objet');

    // Taille physique de l’image imprimée (en mètres)
    const IMAGE_WIDTH_M = 0.12; // 12 cm de large, adapte à ton impression

    // Charge l’image ESGT pour l’API image-tracking
    async function loadTrackedImageBitmap(url){
      const res = await fetch(url);
      const blob = await res.blob();
      return await createImageBitmap(blob);
    }

    scene.addEventListener('enter-vr', async () => {
      // Assure-toi qu’on est bien en session AR
      const session = scene.renderer.xr.getSession();
      if (!session) { hud.textContent = "Pas de session ARWebXR."; return; }

      // Prépare l’image à suivre
      const imgBitmap = await loadTrackedImageBitmap('./esgt-target.png');

      // Ajoute l’image aux “trackedImages” de la session (Chrome Android)
      try{
        await session.updateTargetImage(imgBitmap, IMAGE_WIDTH_M);
        // Certains builds utilisent plutôt requestSession avec trackedImages directement ;
        // A-Frame gère la session pour nous, donc on passe par updateTargetImage().
      }catch(e){
        console.warn('updateTargetImage non supporté, on tente l’ancienne voie', e);
      }

      // Espace de référence
      const refSpace = await session.requestReferenceSpace('local');

      // Écoute les “tracked images” à chaque frame
      scene.renderer.setAnimationLoop((t, frame) => {
        if (!frame) return;
        const results = frame.getImageTrackingResults ? frame.getImageTrackingResults() : [];

        for (const result of results) {
          // Chaque result correspond à UNE image suivie (ici on n’en a qu’une)
          const state = result.trackingState; // "tracked" | "emulated" | "not-tracked"
          const pose  = frame.getPose(result.imageSpace || result, refSpace);
          if (!pose) continue;

          // Positionne le pivot à la pose du CENTRE DE L’IMAGE (origine du repère)
          pivot.object3D.position.set(
            pose.transform.position.x,
            pose.transform.position.y,
            pose.transform.position.z
          );
          pivot.object3D.quaternion.set(
            pose.transform.orientation.x,
            pose.transform.orientation.y,
            pose.transform.orientation.z,
            pose.transform.orientation.w
          );

          // Crée/attache une ANCRE AR à cette pose (pour la stabilité hors-champ)
          if (!pivot.anchor) {
            session.requestAnchor
              ? session.requestAnchor(pose.transform, refSpace).then(anchor => {
                  pivot.anchor = anchor;
                  // Suivre automatiquement les updates de l’ancre
                  const anchorSet = frame.trackedAnchors || session.trackedAnchors;
                  if (anchorSet && anchorSet.has && anchorSet.size !== undefined) {
                    // boucle d’update : A-Frame relira la pose via pivot.object3D (ci-dessous)
                  }
                })
              : console.warn('Anchors non supportés sur cette version.');
          }

          // Affiche pivot + objet (l’objet a un OFFSET relatif au pivot dans le HTML)
          if (!pivot.getAttribute('visible'))  pivot.setAttribute('visible', true);
          if (!objet.getAttribute('visible'))  objet.setAttribute('visible', true);

          // IMPORTANT : on garde l’objet comme ENFANT LOGIQUE du pivot (repère cible)
          // → en A-Frame, on peut simplement forcer le parentage côté object3D:
          if (objet.object3D.parent !== pivot.object3D) {
            pivot.object3D.add(objet.object3D);
          }

          hud.textContent = (state === 'tracked')
            ? 'Image ESGT suivie (ancre posée). Déplace-toi : l’objet reste sur la table.'
            : 'Tracking approximatif… bouge doucement et garde une bonne lumière.';
        }
      });
    });
  </script>
</body>
</html>
